"""
QuantumDice â€“ demo (v0.1)
========================

Cel:
- Mamy 5 funkcji (strategii) rozwiÄ…zujÄ…cych ten sam problem.
- QuantumDice wybiera tÄ™, ktÃ³ra ma najwiÄ™kszÄ… "jakoÅ›Ä‡ decyzji" przy rozsÄ…dnym koszcie.

Problem demo:
- Minimalizacja funkcji f(x) na przedziale [a, b].

5 strategii:
1) random_search
2) hill_climb
3) simulated_annealing
4) golden_section_search  (bardzo mocna na unimodalne funkcje)
5) grid_search

Uruchomienie:
    python quantumdice_demo.py

Wynik:
- Ranking strategii z metrykami + wybrana strategia.
"""

from __future__ import annotations
from dataclasses import dataclass
from typing import Callable, Dict, List, Tuple
import math
import random
import statistics
import time


# -----------------------------
# 1) Problem (funkcja celu)
# -----------------------------

def objective(x: float) -> float:
    """
    Funkcja celu: mieszanka 'Å‚adnej doliny' + lokalne zakÅ‚Ã³cenia.
    Ma sens w demo, bo czÄ™Å›Ä‡ metod moÅ¼e siÄ™ nabraÄ‡ na lokalne minima.

    Minimum globalne jest w praktyce do znalezienia, ale nie jest "za Å‚atwe".
    """
    # bazowa dolina
    base = (x - 1.7) ** 2
    # drobne fale (lokalne minima)
    ripple = 0.15 * math.sin(8 * x) + 0.08 * math.sin(22 * x)
    return base + ripple


# -----------------------------
# 2) Struktury danych
# -----------------------------

@dataclass(frozen=True)
class SolveResult:
    """
    Wynik pojedynczego uruchomienia (1 rollout).
    """
    x_best: float
    f_best: float
    evaluations: int
    duration_ms: float


@dataclass
class StrategyStats:
    """
    Agregacja wielu rolloutÃ³w danej strategii.
    """
    name: str
    results: List[SolveResult]

    def summary(self) -> Dict[str, float]:
        f_vals = [r.f_best for r in self.results]
        evals = [r.evaluations for r in self.results]
        durs = [r.duration_ms for r in self.results]

        return {
            "f_best_mean": statistics.mean(f_vals),
            "f_best_min": min(f_vals),
            "f_best_std": statistics.pstdev(f_vals) if len(f_vals) > 1 else 0.0,
            "eval_mean": statistics.mean(evals),
            "dur_ms_mean": statistics.mean(durs),
        }


# -----------------------------
# 3) PiÄ™Ä‡ strategii (funkcji)
# -----------------------------

def random_search(f: Callable[[float], float], a: float, b: float, budget: int, rng: random.Random) -> SolveResult:
    """
    Strategia 1: Random Search
    - najprostsza: losujemy punkty i bierzemy najlepszy
    - plus: nie grzÄ™Åºnie w lokalnych minimach (bo skacze)
    - minus: moÅ¼e byÄ‡ maÅ‚o efektywna w gÅ‚adkich problemach
    """
    start = time.perf_counter()
    x_best = None
    f_best = float("inf")
    for _ in range(budget):
        x = rng.uniform(a, b)
        fx = f(x)
        if fx < f_best:
            f_best = fx
            x_best = x
    dur_ms = (time.perf_counter() - start) * 1000
    return SolveResult(x_best=x_best, f_best=f_best, evaluations=budget, duration_ms=dur_ms)


def grid_search(f: Callable[[float], float], a: float, b: float, budget: int, rng: random.Random) -> SolveResult:
    """
    Strategia 2: Grid Search (siatka)
    - deterministycznie skanuje przedziaÅ‚ w rÃ³wnych krokach
    - plus: stabilna (maÅ‚a wariancja)
    - minus: nie adaptuje siÄ™; jak budÅ¼et maÅ‚y, moÅ¼e "minÄ…Ä‡" dolinÄ™
    """
    start = time.perf_counter()
    if budget < 2:
        budget = 2
    step = (b - a) / (budget - 1)
    x_best = a
    f_best = f(a)
    evals = 1

    for i in range(1, budget):
        x = a + i * step
        fx = f(x)
        evals += 1
        if fx < f_best:
            f_best = fx
            x_best = x

    dur_ms = (time.perf_counter() - start) * 1000
    return SolveResult(x_best=x_best, f_best=f_best, evaluations=evals, duration_ms=dur_ms)


def hill_climb(f: Callable[[float], float], a: float, b: float, budget: int, rng: random.Random) -> SolveResult:
    """
    Strategia 3: Hill Climbing (w praktyce: gradient-free local search)
    - start w losowym punkcie, potem lokalne kroki +/- step, step maleje
    - plus: szybko poprawia wynik, jeÅ›li start jest "sensowny"
    - minus: lubi utknÄ…Ä‡ w lokalnym minimum
    """
    start = time.perf_counter()

    x = rng.uniform(a, b)
    fx = f(x)
    evals = 1

    step = (b - a) * 0.1  # startowy rozmiar kroku
    x_best, f_best = x, fx

    # kaÅ¼da iteracja zuÅ¼ywa 1 lub 2 ewaluacje, wiÄ™c pilnujemy budÅ¼etu
    while evals < budget and step > 1e-9:
        # sprÃ³buj w lewo i w prawo
        candidates = []
        if evals < budget:
            xl = max(a, x - step)
            fl = f(xl); evals += 1
            candidates.append((xl, fl))
        if evals < budget:
            xr = min(b, x + step)
            fr = f(xr); evals += 1
            candidates.append((xr, fr))

        # wybierz najlepszy ruch, jeÅ›li poprawia
        x_new, f_new = min(candidates, key=lambda t: t[1])
        if f_new < fx:
            x, fx = x_new, f_new
            if fx < f_best:
                x_best, f_best = x, fx
        else:
            # brak poprawy: zmniejszamy krok (schodzimy do drobniejszej skali)
            step *= 0.5

    dur_ms = (time.perf_counter() - start) * 1000
    return SolveResult(x_best=x_best, f_best=f_best, evaluations=evals, duration_ms=dur_ms)


def simulated_annealing(f: Callable[[float], float], a: float, b: float, budget: int, rng: random.Random) -> SolveResult:
    """
    Strategia 4: Simulated Annealing
    - lokalne kroki, ale czasem akceptujemy gorszy wynik (ucieczka z puÅ‚apek)
    - temperatura maleje => z czasem stajemy siÄ™ bardziej "zachowawczy"
    """
    start = time.perf_counter()

    x = rng.uniform(a, b)
    fx = f(x)
    evals = 1

    x_best, f_best = x, fx

    # parametry annealingu (proste, ale dziaÅ‚ajÄ…ce w demo)
    T0 = 1.0
    step0 = (b - a) * 0.15

    k = 0
    while evals < budget:
        # temperatura i krok malejÄ… z iteracjÄ…
        t = T0 * (0.995 ** k)
        step = step0 * (0.997 ** k)

        # propozycja ruchu
        x_new = x + rng.uniform(-step, step)
        x_new = min(b, max(a, x_new))
        f_new = f(x_new)
        evals += 1

        # kryterium akceptacji
        delta = f_new - fx
        if delta < 0:
            accept = True
        else:
            # im wyÅ¼sza temperatura, tym chÄ™tniej przyjmujemy gorsze rozwiÄ…zania
            accept_prob = math.exp(-delta / max(t, 1e-12))
            accept = rng.random() < accept_prob

        if accept:
            x, fx = x_new, f_new
            if fx < f_best:
                x_best, f_best = x, fx

        k += 1

    dur_ms = (time.perf_counter() - start) * 1000
    return SolveResult(x_best=x_best, f_best=f_best, evaluations=evals, duration_ms=dur_ms)


def golden_section_search(f: Callable[[float], float], a: float, b: float, budget: int, rng: random.Random) -> SolveResult:
    """
    Strategia 5: Golden Section Search
    - klasyk dla funkcji unimodalnych na przedziale
    - adaptacyjnie zwÄ™Å¼a przedziaÅ‚ poszukiwaÅ„ bez pochodnych
    - uwaga: przy wielu lokalnych minimach moÅ¼e zwÄ™Å¼aÄ‡ siÄ™ w zÅ‚Ä… dolinÄ™,
      ale czÄ™sto i tak daje Å›wietny wynik w gÅ‚adkich problemach.

    W demo dziaÅ‚a zaskakujÄ…co dobrze, bo dolina bazowa dominuje.
    """
    start = time.perf_counter()

    phi = (1 + math.sqrt(5)) / 2
    invphi = 1 / phi

    # inicjalizacja punktÃ³w
    c = b - (b - a) * invphi
    d = a + (b - a) * invphi
    fc = f(c)
    fd = f(d)
    evals = 2

    x_best, f_best = (c, fc) if fc < fd else (d, fd)

    while evals < budget and abs(b - a) > 1e-12:
        if fc < fd:
            # minimum jest w [a, d]
            b, d, fd = d, c, fc
            c = b - (b - a) * invphi
            fc = f(c); evals += 1
            if fc < f_best:
                x_best, f_best = c, fc
        else:
            # minimum jest w [c, b]
            a, c, fc = c, d, fd
            d = a + (b - a) * invphi
            fd = f(d); evals += 1
            if fd < f_best:
                x_best, f_best = d, fd

    dur_ms = (time.perf_counter() - start) * 1000
    return SolveResult(x_best=x_best, f_best=f_best, evaluations=evals, duration_ms=dur_ms)


# -----------------------------
# 4) QuantumDice â€“ wybÃ³r strategii
# -----------------------------

def quantumdice_score(stats: StrategyStats, w_quality=0.70, w_stability=0.15, w_cost=0.15) -> float:
    """
    RdzeÅ„ QuantumDice: scoring strategii.

    Intuicja (Twoja koncepcja, przeÅ‚oÅ¼ona na praktyczny scoring):
    - QUALITY: jak dobry wynik dostarcza strategia (Å›rednio i w najlepszym rolloucie)
    - STABILITY: jak powtarzalna jest (niska wariancja = mniej "chaosu")
    - COST: ile kosztuje (czas / ewaluacje)

    PoniewaÅ¼ minimalizujemy f(x), "lepsza jakoÅ›Ä‡" = mniejsze f.
    Å»eby zrobiÄ‡ z tego dodatni score: uÅ¼ywamy odwrotnoÅ›ci (1/(eps + f)).
    """
    s = stats.summary()
    eps = 1e-12

    # QUALITY: miks Å›redniego i najlepszego wyniku
    quality = 0.6 * (1 / (eps + s["f_best_mean"])) + 0.4 * (1 / (eps + s["f_best_min"]))

    # STABILITY: im mniejszy std, tym lepiej (odwrotnoÅ›Ä‡)
    stability = 1 / (eps + s["f_best_std"] + 1e-6)

    # COST: Å‚Ä…czymy czas i liczbÄ™ ewaluacji
    # (tu budÅ¼et podobny dla wszystkich, ale czas moÅ¼e siÄ™ rÃ³Å¼niÄ‡)
    cost = 1 / (eps + 0.7 * s["dur_ms_mean"] + 0.3 * s["eval_mean"])

    # SkÅ‚adamy wynik QuantumDice
    return w_quality * quality + w_stability * stability + w_cost * cost


def run_quantumdice(
    f: Callable[[float], float],
    a: float,
    b: float,
    budget: int = 200,
    rollouts: int = 20,
    seed: int = 123,
) -> Tuple[List[Tuple[str, float, Dict[str, float]]], str]:
    """
    Uruchamia wszystkie strategie, zbiera statystyki, liczy scoring i wybiera zwyciÄ™zcÄ™.

    Zwraca:
    - ranking: lista (nazwa, score, summary)
    - winner_name
    """
    strategies: Dict[str, Callable[..., SolveResult]] = {
        "random_search": random_search,
        "grid_search": grid_search,
        "hill_climb": hill_climb,
        "simulated_annealing": simulated_annealing,
        "golden_section_search": golden_section_search,
    }

    rng_master = random.Random(seed)
    all_stats: List[StrategyStats] = []

    for name, fn in strategies.items():
        # KaÅ¼da strategia dostaje wÅ‚asny RNG, ale z deterministycznym seedem
        # Å¼eby wyniki byÅ‚y powtarzalne miÄ™dzy uruchomieniami.
        strategy_rng = random.Random(rng_master.randint(0, 10**9))

        results: List[SolveResult] = []
        for _ in range(rollouts):
            # Dla kaÅ¼dego rolloutu jeszcze jeden seed (kontrolowana rÃ³Å¼norodnoÅ›Ä‡)
            rollout_rng = random.Random(strategy_rng.randint(0, 10**9))
            res = fn(f=f, a=a, b=b, budget=budget, rng=rollout_rng)
            results.append(res)

        all_stats.append(StrategyStats(name=name, results=results))

    ranking = []
    for st in all_stats:
        score = quantumdice_score(st)
        ranking.append((st.name, score, st.summary()))

    # sort malejÄ…co po score
    ranking.sort(key=lambda t: t[1], reverse=True)

    winner_name = ranking[0][0]
    return ranking, winner_name


# -----------------------------
# 5) Prezentacja wynikÃ³w
# -----------------------------

def pretty_print_ranking(ranking: List[Tuple[str, float, Dict[str, float]]]) -> None:
    print("\nQuantumDice Ranking (higher = better) ğŸ²")
    print("=" * 72)
    print(f"{'Strategy':24} {'Score':>12} | {'f_mean':>10} {'f_min':>10} {'std':>10}")
    print("-" * 72)
    for name, score, s in ranking:
        print(
            f"{name:24} {score:12.4f} | "
            f"{s['f_best_mean']:10.6f} {s['f_best_min']:10.6f} {s['f_best_std']:10.6f}"
        )
    print("=" * 72)


def show_winner_details(ranking: List[Tuple[str, float, Dict[str, float]]], winner: str) -> None:
    # znajdÅº zwyciÄ™zcÄ™
    for name, score, s in ranking:
        if name == winner:
            print(f"\nWinner: {winner} ğŸ†")
            print(f"Score: {score:.4f}")
            print("Why it won (signals):")
            print(f"  - Mean best f(x): {s['f_best_mean']:.6f}")
            print(f"  - Min best  f(x): {s['f_best_min']:.6f}")
            print(f"  - Std (stability): {s['f_best_std']:.6f}")
            print(f"  - Mean evaluations: {s['eval_mean']:.1f}")
            print(f"  - Mean duration ms: {s['dur_ms_mean']:.3f}")
            break


# -----------------------------
# 6) MAIN
# -----------------------------

if __name__ == "__main__":
    # Parametry problemu
    a, b = -2.0, 5.0

    # Parametry QuantumDice
    budget = 200     # ile ewaluacji na rollout (na uruchomienie strategii)
    rollouts = 25    # ile rolloutÃ³w na strategiÄ™ (estymacja stabilnoÅ›ci)
    seed = 42

    print("QuantumDice demo: selecting the best solver among 5 strategies ğŸ²")
    print(f"Domain: [{a}, {b}] | budget={budget} | rollouts={rollouts} | seed={seed}")

    ranking, winner = run_quantumdice(
        f=objective,
        a=a, b=b,
        budget=budget,
        rollouts=rollouts,
        seed=seed
    )

    pretty_print_ranking(ranking)
    show_winner_details(ranking, winner)

    # Pokaz przykÅ‚adowego "uÅ¼ycia zwyciÄ™zcy" na jednej dodatkowej prÃ³bie:
    # (tu tylko demonstrujemy, Å¼e da siÄ™ Å‚atwo odpaliÄ‡ wskazanÄ… strategiÄ™)
    print("\nRunning winner once more for a concrete solution:")
    strategies_map = {
        "random_search": random_search,
        "grid_search": grid_search,
        "hill_climb": hill_climb,
        "simulated_annealing": simulated_annealing,
        "golden_section_search": golden_section_search,
    }
    rng = random.Random(2026)
    res = strategies_map[winner](objective, a, b, budget, rng)
    print(f"  x_best = {res.x_best:.6f}")
    print(f"  f_best = {res.f_best:.6f}")
    print(f"  evaluations = {res.evaluations}")
    print(f"  duration_ms = {res.duration_ms:.3f}")
    print("\nDone.")
